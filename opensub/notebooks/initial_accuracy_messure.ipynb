{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T00:38:34.041715Z",
     "start_time": "2025-06-05T00:38:33.295442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Paths to your filtered TSV files\n",
    "SLANG_FILE = r\"C:\\Users\\yozev\\PycharmProjects\\Probing-Slang-Ambiguity-in-LLM\\opensub\\data\\slang_OpenSub_filtered.tsv\"\n",
    "NON_SLANG_FILE = r\"C:\\Users\\yozev\\PycharmProjects\\Probing-Slang-Ambiguity-in-LLM\\opensub\\data\\slang_OpenSub_negatives_filtered.tsv\"\n",
    "\n",
    "# 1) Load both datasets\n",
    "df_slang = pd.read_csv(SLANG_FILE, sep=\"\\t\", dtype=str)\n",
    "df_nonslang = pd.read_csv(NON_SLANG_FILE, sep=\"\\t\", dtype=str)\n",
    "\n",
    "# 2) Assign labels: 1 = slang, 0 = non-slang\n",
    "df_slang[\"label\"] = 1\n",
    "df_nonslang[\"label\"] = 0\n",
    "\n",
    "# 3) Concatenate into one DataFrame\n",
    "df_all = pd.concat([df_slang, df_nonslang], ignore_index=True)\n",
    "\n",
    "# 4) Extract sentences and true labels\n",
    "sentences = df_all[\"SENTENCE\"].tolist()\n",
    "true_labels = df_all[\"label\"].tolist()\n",
    "\n",
    "# 5) Load tokenizer & model (PyTorch) for zero-shot (MNLI) classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "\n",
    "candidate_labels = [\"slang\", \"non-slang\"]\n",
    "\n",
    "def zero_shot_classify(sentence: str, labels: list[str]) -> int:\n",
    "    \"\"\"\n",
    "    Returns 1 if 'slang' is predicted, 0 if 'non-slang' is predicted.\n",
    "    We encode each (sentence, hypothesis) pair, run through the MNLI head,\n",
    "    and pick the label whose entailment logit is highest.\n",
    "    \"\"\"\n",
    "    # Build hypotheses like \"This example is slang.\" and \"This example is non-slang.\"\n",
    "    hypotheses = [f\"This example is {lbl}.\" for lbl in labels]\n",
    "    # Tokenize: pair each hypothesis with the same sentence\n",
    "    encoded = tokenizer(\n",
    "        [sentence] * len(hypotheses),\n",
    "        hypotheses,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded)\n",
    "        logits = outputs.logits  # shape: (len(labels), 3)\n",
    "        # For BART-MNLI, the label mapping is [contradiction, neutral, entailment]\n",
    "        entail_logits = logits[:, 2]  # get \"entailment\" logit for each hypothesis\n",
    "        probs = F.softmax(entail_logits, dim=0)  # softmax over the entailment scores\n",
    "        best_idx = torch.argmax(probs).item()\n",
    "\n",
    "    return 1 if labels[best_idx] == \"slang\" else 0\n",
    "\n",
    "# 6) Run all sentences through zero-shot classifier\n",
    "predicted_labels = []\n",
    "for sent in sentences:\n",
    "    pred = zero_shot_classify(sent, candidate_labels)\n",
    "    predicted_labels.append(pred)\n",
    "\n",
    "# 7) Compute and print accuracy\n",
    "acc = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'sym_float' from 'torch' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n",
      "File \u001B[1;32m~\\.conda\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# mypy: allow-untyped-defs\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodules\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparameter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      4\u001B[0m     Parameter \u001B[38;5;28;01mas\u001B[39;00m Parameter,\n\u001B[0;32m      5\u001B[0m     UninitializedParameter \u001B[38;5;28;01mas\u001B[39;00m UninitializedParameter,\n\u001B[0;32m      6\u001B[0m     UninitializedBuffer \u001B[38;5;28;01mas\u001B[39;00m UninitializedBuffer,\n\u001B[0;32m      7\u001B[0m )\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparallel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataParallel \u001B[38;5;28;01mas\u001B[39;00m DataParallel\n",
      "File \u001B[1;32m~\\.conda\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Module\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Identity, Linear, Bilinear, LazyLinear\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Conv1d, Conv2d, Conv3d, \\\n\u001B[0;32m      4\u001B[0m     ConvTranspose1d, ConvTranspose2d, ConvTranspose3d, \\\n\u001B[0;32m      5\u001B[0m     LazyConv1d, LazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d, LazyConvTranspose3d\n",
      "File \u001B[1;32m~\\.conda\\envs\\gpu_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mweakref\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_prims_common\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DeviceLikeType\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparameter\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Parameter\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhooks\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\gpu_env\\lib\\site-packages\\torch\\_prims_common\\__init__.py:36\u001B[0m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sym_float, sym_int, sym_max\n\u001B[0;32m     39\u001B[0m ShapeType: TypeAlias \u001B[38;5;241m=\u001B[39m Union[torch\u001B[38;5;241m.\u001B[39mSize, List[\u001B[38;5;28mint\u001B[39m], Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]]\n\u001B[0;32m     40\u001B[0m StrideType: TypeAlias \u001B[38;5;241m=\u001B[39m Union[List[\u001B[38;5;28mint\u001B[39m], Tuple[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]]\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'sym_float' from 'torch' (unknown location)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T00:38:46.728488Z",
     "start_time": "2025-06-05T00:38:39.295169Z"
    }
   },
   "cell_type": "code",
   "source": "!conda install -y pytorch torchvision torchaudio cudatoolkit=11.8 -c pytorch --debug\n",
   "id": "194cfd5f7caf2463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T00:38:53.677551Z",
     "start_time": "2025-06-05T00:38:53.449132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())"
   ],
   "id": "4125904cdecc19ec",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__version__\u001B[49m, torch\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m.\u001B[39mcuda, torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available())\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute '__version__'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Environment",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
