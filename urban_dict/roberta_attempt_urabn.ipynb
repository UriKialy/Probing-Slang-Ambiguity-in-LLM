{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-03T17:09:57.392846Z",
     "start_time": "2025-06-03T17:09:57.386387Z"
    }
   },
   "source": [
    "# Cell 1: Imports\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm.auto import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:10:00.390268Z",
     "start_time": "2025-06-03T17:10:00.381487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Load your CSV\n",
    "csv_path = r\"C:\\Users\\yozev\\PycharmProjects\\Slang_in_LLMs\\filtered_slang.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "if \"sentence\" not in df.columns:\n",
    "    raise ValueError(\"Your CSV must have a column named 'sentence'.\")\n",
    "sentences = df[\"sentence\"].astype(str).tolist()\n"
   ],
   "id": "eb0973eb832bf63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:25:58.429581Z",
     "start_time": "2025-06-03T17:10:03.227267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Define two zero‐shot classifiers using purely PyTorch‐based MNLI models\n",
    "\n",
    "# 1) facebook/bart-large-mnli (pure PyTorch; will never import TensorFlow)\n",
    "bart_nli = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# 2) joeddav/xlm-roberta-large-xnli (pure PyTorch; also never loads TensorFlow)\n",
    "xlmroberta_nli = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"joeddav/xlm-roberta-large-xnli\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# We will ask each model to choose between these two labels:\n",
    "labels = [\"contains slang\", \"does not contain slang\"]"
   ],
   "id": "84494c7bfbc69369",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7e53139e51041e3b00e3780a64a9b2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yozev\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yozev\\.cache\\huggingface\\hub\\models--facebook--bart-large-mnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9de0e301ce92488383ae05587ab859ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "598a7e05ffed4212aa4346036ed8ba39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b29bdb426a14ef58ca76cac95c2d6d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9890461223c47448e722ccbbb39bb48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef6e6d66d9fa4b98b19449a47b7fb13f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yozev\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91e9c9875c3947228b1e85edb603050b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yozev\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yozev\\.cache\\huggingface\\hub\\models--joeddav--xlm-roberta-large-xnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea5b5ca656be4ad6b8f43fd20b5f4fea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40dae043a33844ea829f7fc6cff132a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5eb3f5aacc3e4faa93f23630a953eea0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7da392556cca44cbaf8af7e7dd00d3dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:31:48.081847Z",
     "start_time": "2025-06-03T17:26:05.166431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 4: Run predictions on every sentence\n",
    "results = []\n",
    "\n",
    "for sent in tqdm(sentences, desc=\"Classifying sentences\"):\n",
    "    # BART-MNLI prediction\n",
    "    out_bart = bart_nli(sent, candidate_labels=labels)\n",
    "    pred_bart = out_bart[\"labels\"][0]        # top label\n",
    "\n",
    "    # XLM-RoBERTa-XNLI prediction\n",
    "    out_xlm = xlmroberta_nli(sent, candidate_labels=labels)\n",
    "    pred_xlm = out_xlm[\"labels\"][0]          # top label\n",
    "\n",
    "    # All sentences truly contain slang\n",
    "    truth = \"contains slang\"\n",
    "\n",
    "    results.append({\n",
    "        \"sentence\":            sent,\n",
    "        \"bart_pred\":           pred_bart,\n",
    "        \"xlmroberta_pred\":     pred_xlm,\n",
    "        \"ground_truth\":        truth,\n",
    "        \"bart_correct\":        (pred_bart == truth),\n",
    "        \"xlmroberta_correct\":  (pred_xlm == truth)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ],
   "id": "baa711189e588eb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifying sentences:   0%|          | 0/238 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c887434dbfe74e9987000af89ff705cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:31:50.528800Z",
     "start_time": "2025-06-03T17:31:50.500921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 5: Compute and print each model’s accuracy\n",
    "total = len(results_df)\n",
    "bart_acc = results_df[\"bart_correct\"].sum() / total\n",
    "xlmroberta_acc = results_df[\"xlmroberta_correct\"].sum() / total\n",
    "\n",
    "print(f\"BART-MNLI accuracy:       {bart_acc:.2%}\")\n",
    "print(f\"XLM-RoBERTa-XNLI accuracy: {xlmroberta_acc:.2%}\")\n"
   ],
   "id": "d8921162edc024b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BART-MNLI accuracy:       98.74%\n",
      "XLM-RoBERTa-XNLI accuracy: 90.34%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T17:31:57.241518Z",
     "start_time": "2025-06-03T17:31:57.220858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 6 (optional): Inspect the first few rows\n",
    "results_df.head(10)"
   ],
   "id": "50cbbf1e7d7720",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            sentence       bart_pred  \\\n",
       "0  1. I can smell your dank all the way over here...  contains slang   \n",
       "1                                         \"you tool\"  contains slang   \n",
       "2  He was telling me his trash about my sense of ...  contains slang   \n",
       "3  Nathan says Tom’s phone voice is touch; it sta...  contains slang   \n",
       "4  The budget for a trade show booth this year is...  contains slang   \n",
       "5  Person 1: Ey yo bish why u not at scool tis mo...  contains slang   \n",
       "6                          i wanna get a ripped body  contains slang   \n",
       "7  \"Safe Jo.\\r\\nSafe Steve.\\r\\nSafe.\\r\\nYeah safe...  contains slang   \n",
       "8                             Megan gave Simon head.  contains slang   \n",
       "9  Yo these pills you grabbed are pressed eh... i...  contains slang   \n",
       "\n",
       "  xlmroberta_pred    ground_truth  bart_correct  xlmroberta_correct  \n",
       "0  contains slang  contains slang          True                True  \n",
       "1  contains slang  contains slang          True                True  \n",
       "2  contains slang  contains slang          True                True  \n",
       "3  contains slang  contains slang          True                True  \n",
       "4  contains slang  contains slang          True                True  \n",
       "5  contains slang  contains slang          True                True  \n",
       "6  contains slang  contains slang          True                True  \n",
       "7  contains slang  contains slang          True                True  \n",
       "8  contains slang  contains slang          True                True  \n",
       "9  contains slang  contains slang          True                True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>bart_pred</th>\n",
       "      <th>xlmroberta_pred</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>bart_correct</th>\n",
       "      <th>xlmroberta_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. I can smell your dank all the way over here...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"you tool\"</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He was telling me his trash about my sense of ...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nathan says Tom’s phone voice is touch; it sta...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The budget for a trade show booth this year is...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Person 1: Ey yo bish why u not at scool tis mo...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i wanna get a ripped body</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Safe Jo.\\r\\nSafe Steve.\\r\\nSafe.\\r\\nYeah safe...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Megan gave Simon head.</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yo these pills you grabbed are pressed eh... i...</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>contains slang</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
