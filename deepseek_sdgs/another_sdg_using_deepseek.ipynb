{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T00:20:50.041877Z",
     "start_time": "2025-06-03T23:40:13.667426Z"
    }
   },
   "source": [
    "# ## 1. Install Required Packages\n",
    "# !pip install transformers torch pandas tqdm\n",
    "\n",
    "# ## 2. Imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig\n",
    "\n",
    "\n",
    "# ## 3. Define the Slang Words \n",
    "slang_words = [\n",
    "    \"bad\", \"bang\", \"beat\", \"bet\", \"blow\", \"bomb\", \"booked\", \"bounce\", \"bread\", \"broke\",\n",
    "    \"burn\", \"buzz\", \"calm\", \"cap\", \"catch\", \"check\", \"chef\", \"chill\", \"clap\", \"clean\",\n",
    "    \"clutch\", \"cold\", \"come\", \"cook\", \"cool\", \"crack\", \"cringe\", \"cut\", \"dank\", \"dark\",\n",
    "    \"dead\", \"deadass\", \"dope\", \"drag\", \"draw\", \"drip\", \"drop\", \"dust\", \"extra\", \"fam\",\n",
    "    \"fire\", \"fit\", \"flex\", \"gas\", \"ghost\", \"glow\", \"grind\", \"grub\", \"hard\", \"hater\",\n",
    "    \"head\", \"hit\", \"hot\", \"jam\", \"kick\", \"kill\", \"light\", \"link\", \"lit\", \"live\",\n",
    "    \"loaded\", \"long\", \"loop\", \"loud\", \"lowkey\", \"mad\", \"man\", \"mood\", \"move\", \"off\",\n",
    "    \"peak\", \"pop\", \"press\", \"pressed\", \"pull\", \"quiet\", \"ride\", \"ripped\", \"roll\", \"run\",\n",
    "    \"safe\", \"salty\", \"savage\", \"secure\", \"serve\", \"shade\", \"shook\", \"sick\", \"slaps\",\n",
    "    \"slay\", \"slide\", \"smoke\", \"snap\", \"snack\", \"soft\", \"spill\", \"squad\", \"stack\",\n",
    "    \"stale\", \"stan\", \"stick\", \"sus\", \"swag\", \"tea\", \"thick\", \"thin\", \"thirsty\", \"tight\",\n",
    "    \"ting\", \"tool\", \"touch\", \"trash\", \"trip\", \"turnt\", \"vibe\", \"wave\", \"wet\", \"whip\",\n",
    "    \"woke\", \"work\", \"bag\", \"bars\", \"base\", \"brick\", \"cake\", \"cheese\", \"dash\", \"dip\",\n",
    "    \"fade\", \"game\", \"heat\", \"ice\", \"juice\", \"plug\", \"poppin\", \"rack\", \"sauce\", \"score\",\n",
    "    \"shine\", \"trap\"\n",
    "]\n",
    "\n",
    "# ## 4. Choose a Hugging Face Text-Generation Model (DeepSeek-R1-0528)\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-0528\"\n",
    "\n",
    "# Load config first\n",
    "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Remove quantization config if it exists\n",
    "if hasattr(config, 'quantization_config'):\n",
    "    del config.quantization_config\n",
    "\n",
    "# Load tokenizer as before\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
    "\n",
    "# Load model with trust_remote_code=True so DeepSeek’s custom files are executed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float32,\n",
    "    config=config\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# ## 5. Prompt Templates\n",
    "slang_template = (\n",
    "    \"Write a single sentence that uses the word “{word}” in a slang/idiomatic sense. \"\n",
    "    \"Make it ambiguous so that someone might not be sure if it’s literal or slang.\\n\\n\"\n",
    "    \"Sentence: \"\n",
    ")\n",
    "literal_template = (\n",
    "    \"Write a single sentence that uses the word “{word}” in a purely literal sense \"\n",
    "    \"(no slang meaning). Make it ambiguous enough that someone might mistake it for slang.\\n\\n\"\n",
    "    \"Sentence: \"\n",
    ")\n",
    "\n",
    "# ## 6. Function to Generate One Sentence per Prompt\n",
    "def generate_sentence(prompt: str, max_length: int = 50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    # We’ll do greedy decoding so it’s deterministic (no sampling)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_length=inputs[\"input_ids\"].shape[-1] + max_length,\n",
    "            do_sample=False,\n",
    "            temperature=0.7,    # You can raise/lower for creativity\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    # Drop the prompt tokens to keep only newly generated tokens\n",
    "    gen_tokens = outputs[0][inputs[\"input_ids\"].shape[-1] :]\n",
    "    text = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
    "    # Sometimes the model writes more than one sentence—keep only up to the first period/question/exclamation.\n",
    "    for sep in [\".\", \"?\", \"!\"]:\n",
    "        if sep in text:\n",
    "            text = text.split(sep)[0].strip() + sep\n",
    "            break\n",
    "    return text\n",
    "\n",
    "# ## 7. Build Exactly 2 500 Slang and 2 500 Literal Examples\n",
    "NUM_TOTAL = 5000\n",
    "NUM_PER_CLASS = NUM_TOTAL // 2  # 2 500 slang and 2 500 literal\n",
    "sentences = []\n",
    "labels = []\n",
    "\n",
    "# We’ll cycle through `slang_words` randomly until we collect 2 500 of each type.\n",
    "random.shuffle(slang_words)\n",
    "slang_count = 0\n",
    "literal_count = 0\n",
    "i = 0\n",
    "\n",
    "pbar = tqdm(total=NUM_TOTAL, desc=\"Generating sentences\")\n",
    "while slang_count < NUM_PER_CLASS or literal_count < NUM_PER_CLASS:\n",
    "    word = slang_words[i % len(slang_words)]\n",
    "    i += 1\n",
    "\n",
    "    # Generate one slang-sense example if we still need slang\n",
    "    if slang_count < NUM_PER_CLASS:\n",
    "        prompt = slang_template.format(word=word)\n",
    "        sent = generate_sentence(prompt)\n",
    "        sentences.append(sent)\n",
    "        labels.append(1)  # 1 = slang\n",
    "        slang_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Generate one literal-sense example if we still need literal\n",
    "    if literal_count < NUM_PER_CLASS:\n",
    "        prompt = literal_template.format(word=word)\n",
    "        sent = generate_sentence(prompt)\n",
    "        sentences.append(sent)\n",
    "        labels.append(0)  # 0 = literal\n",
    "        literal_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ## 8. Shuffle the Combined List and Create a DataFrame\n",
    "combined = list(zip(sentences, labels))\n",
    "random.shuffle(combined)\n",
    "sentences_shuffled, labels_shuffled = zip(*combined)\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    \"sentence\": sentences_shuffled,\n",
    "    \"binary\": labels_shuffled\n",
    "})\n",
    "\n",
    "# ## 9. Quick Sanity Check (peek at a few rows)\n",
    "print(\"Total rows:\", len(df_out))\n",
    "display(df_out.head(10))\n",
    "\n",
    "# ## 10. Save to CSV\n",
    "output_path = \"slang_literal_benchmark_5000.csv\"\n",
    "df_out.to_csv(output_path, index=False)\n",
    "print(f\"Saved dataset to {output_path}\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/163 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5958c9142b0242ae96554898fe572815"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-000163.safetensors:   0%|          | 21.0M/5.26G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b3eb132d94574c5eb9c5ea0780e2210e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yozev\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yozev\\.cache\\huggingface\\hub\\models--deepseek-ai--DeepSeek-R1-0528. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-000163.safetensors:   0%|          | 0.00/4.30G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca8ecbac11c844bc9fb8af4ba7d53d05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 46\u001B[0m\n\u001B[0;32m     43\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_name, use_fast\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Load model with trust_remote_code=True so DeepSeek’s custom files are executed\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m     47\u001B[0m     model_name,\n\u001B[0;32m     48\u001B[0m     trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     49\u001B[0m     torch_dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32,\n\u001B[0;32m     50\u001B[0m     config\u001B[38;5;241m=\u001B[39mconfig\n\u001B[0;32m     51\u001B[0m )\n\u001B[0;32m     52\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     54\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\auto_factory.py:559\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mregister(config\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, model_class, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    558\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m add_generation_mixin_to_remote_model(model_class)\n\u001B[1;32m--> 559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[0;32m    560\u001B[0m         pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39mmodel_args, config\u001B[38;5;241m=\u001B[39mconfig, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mhub_kwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    561\u001B[0m     )\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py:3769\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3766\u001B[0m \u001B[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001B[39;00m\n\u001B[0;32m   3767\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sharded:\n\u001B[0;32m   3768\u001B[0m     \u001B[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001B[39;00m\n\u001B[1;32m-> 3769\u001B[0m     resolved_archive_file, sharded_metadata \u001B[38;5;241m=\u001B[39m get_checkpoint_shard_files(\n\u001B[0;32m   3770\u001B[0m         pretrained_model_name_or_path,\n\u001B[0;32m   3771\u001B[0m         resolved_archive_file,\n\u001B[0;32m   3772\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   3773\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   3774\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   3775\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[0;32m   3776\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m   3777\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   3778\u001B[0m         user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[0;32m   3779\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   3780\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n\u001B[0;32m   3781\u001B[0m         _commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[0;32m   3782\u001B[0m     )\n\u001B[0;32m   3784\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3785\u001B[0m     is_safetensors_available()\n\u001B[0;32m   3786\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resolved_archive_file, \u001B[38;5;28mstr\u001B[39m)\n\u001B[0;32m   3787\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m resolved_archive_file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.safetensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   3788\u001B[0m ):\n\u001B[0;32m   3789\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m safe_open(resolved_archive_file, framework\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:1098\u001B[0m, in \u001B[0;36mget_checkpoint_shard_files\u001B[1;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m   1095\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m shard_filename \u001B[38;5;129;01min\u001B[39;00m tqdm(shard_filenames, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading shards\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m show_progress_bar):\n\u001B[0;32m   1096\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1097\u001B[0m         \u001B[38;5;66;03m# Load from URL\u001B[39;00m\n\u001B[1;32m-> 1098\u001B[0m         cached_filename \u001B[38;5;241m=\u001B[39m cached_file(\n\u001B[0;32m   1099\u001B[0m             pretrained_model_name_or_path,\n\u001B[0;32m   1100\u001B[0m             shard_filename,\n\u001B[0;32m   1101\u001B[0m             cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   1102\u001B[0m             force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   1103\u001B[0m             proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   1104\u001B[0m             resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[0;32m   1105\u001B[0m             local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m   1106\u001B[0m             token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   1107\u001B[0m             user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[0;32m   1108\u001B[0m             revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   1109\u001B[0m             subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n\u001B[0;32m   1110\u001B[0m             _commit_hash\u001B[38;5;241m=\u001B[39m_commit_hash,\n\u001B[0;32m   1111\u001B[0m         )\n\u001B[0;32m   1112\u001B[0m     \u001B[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001B[39;00m\n\u001B[0;32m   1113\u001B[0m     \u001B[38;5;66;03m# we don't have to catch them here.\u001B[39;00m\n\u001B[0;32m   1114\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:403\u001B[0m, in \u001B[0;36mcached_file\u001B[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[0;32m    400\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[1;32m--> 403\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[0;32m    404\u001B[0m         path_or_repo_id,\n\u001B[0;32m    405\u001B[0m         filename,\n\u001B[0;32m    406\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subfolder) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m subfolder,\n\u001B[0;32m    407\u001B[0m         repo_type\u001B[38;5;241m=\u001B[39mrepo_type,\n\u001B[0;32m    408\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m    409\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m    410\u001B[0m         user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[0;32m    411\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m    412\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m    413\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[0;32m    414\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m    415\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m    416\u001B[0m     )\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    418\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[0;32m    112\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1008\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[0m\n\u001B[0;32m    988\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_local_dir(\n\u001B[0;32m    989\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[0;32m    990\u001B[0m         local_dir\u001B[38;5;241m=\u001B[39mlocal_dir,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1005\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m   1006\u001B[0m     )\n\u001B[0;32m   1007\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1008\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _hf_hub_download_to_cache_dir(\n\u001B[0;32m   1009\u001B[0m         \u001B[38;5;66;03m# Destination\u001B[39;00m\n\u001B[0;32m   1010\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[0;32m   1011\u001B[0m         \u001B[38;5;66;03m# File info\u001B[39;00m\n\u001B[0;32m   1012\u001B[0m         repo_id\u001B[38;5;241m=\u001B[39mrepo_id,\n\u001B[0;32m   1013\u001B[0m         filename\u001B[38;5;241m=\u001B[39mfilename,\n\u001B[0;32m   1014\u001B[0m         repo_type\u001B[38;5;241m=\u001B[39mrepo_type,\n\u001B[0;32m   1015\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m   1016\u001B[0m         \u001B[38;5;66;03m# HTTP info\u001B[39;00m\n\u001B[0;32m   1017\u001B[0m         endpoint\u001B[38;5;241m=\u001B[39mendpoint,\n\u001B[0;32m   1018\u001B[0m         etag_timeout\u001B[38;5;241m=\u001B[39metag_timeout,\n\u001B[0;32m   1019\u001B[0m         headers\u001B[38;5;241m=\u001B[39mhf_headers,\n\u001B[0;32m   1020\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   1021\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[0;32m   1022\u001B[0m         \u001B[38;5;66;03m# Additional options\u001B[39;00m\n\u001B[0;32m   1023\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[0;32m   1024\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   1025\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1161\u001B[0m, in \u001B[0;36m_hf_hub_download_to_cache_dir\u001B[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[0m\n\u001B[0;32m   1158\u001B[0m \u001B[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001B[39;00m\n\u001B[0;32m   1160\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m WeakFileLock(lock_path):\n\u001B[1;32m-> 1161\u001B[0m     _download_to_tmp_and_move(\n\u001B[0;32m   1162\u001B[0m         incomplete_path\u001B[38;5;241m=\u001B[39mPath(blob_path \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.incomplete\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1163\u001B[0m         destination_path\u001B[38;5;241m=\u001B[39mPath(blob_path),\n\u001B[0;32m   1164\u001B[0m         url_to_download\u001B[38;5;241m=\u001B[39murl_to_download,\n\u001B[0;32m   1165\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   1166\u001B[0m         headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m   1167\u001B[0m         expected_size\u001B[38;5;241m=\u001B[39mexpected_size,\n\u001B[0;32m   1168\u001B[0m         filename\u001B[38;5;241m=\u001B[39mfilename,\n\u001B[0;32m   1169\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[0;32m   1170\u001B[0m         etag\u001B[38;5;241m=\u001B[39metag,\n\u001B[0;32m   1171\u001B[0m         xet_file_data\u001B[38;5;241m=\u001B[39mxet_file_data,\n\u001B[0;32m   1172\u001B[0m     )\n\u001B[0;32m   1173\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(pointer_path):\n\u001B[0;32m   1174\u001B[0m         _create_symlink(blob_path, pointer_path, new_blob\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1725\u001B[0m, in \u001B[0;36m_download_to_tmp_and_move\u001B[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001B[0m\n\u001B[0;32m   1718\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m xet_file_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1719\u001B[0m             logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m   1720\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mXet Storage is enabled for this repo, but the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhf_xet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m package is not installed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1721\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFalling back to regular HTTP download. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1722\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1723\u001B[0m             )\n\u001B[1;32m-> 1725\u001B[0m         http_get(\n\u001B[0;32m   1726\u001B[0m             url_to_download,\n\u001B[0;32m   1727\u001B[0m             f,\n\u001B[0;32m   1728\u001B[0m             proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[0;32m   1729\u001B[0m             resume_size\u001B[38;5;241m=\u001B[39mresume_size,\n\u001B[0;32m   1730\u001B[0m             headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[0;32m   1731\u001B[0m             expected_size\u001B[38;5;241m=\u001B[39mexpected_size,\n\u001B[0;32m   1732\u001B[0m         )\n\u001B[0;32m   1734\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownload complete. Moving file to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdestination_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1735\u001B[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:494\u001B[0m, in \u001B[0;36mhttp_get\u001B[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001B[0m\n\u001B[0;32m    492\u001B[0m new_resume_size \u001B[38;5;241m=\u001B[39m resume_size\n\u001B[0;32m    493\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 494\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39mconstants\u001B[38;5;241m.\u001B[39mDOWNLOAD_CHUNK_SIZE):\n\u001B[0;32m    495\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk:  \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[0;32m    496\u001B[0m             progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(chunk))\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[1;34m()\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:628\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[1;34m(self, amt, decode_content)\u001B[0m\n\u001B[0;32m    626\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[1;32m--> 628\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(amt\u001B[38;5;241m=\u001B[39mamt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[0;32m    630\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[0;32m    631\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:567\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[0;32m    564\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[1;32m--> 567\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp_read(amt) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    569\u001B[0m         flush_decoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:533\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    532\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[1;32m--> 533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\http\\client.py:466\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    463\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[0;32m    465\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[1;32m--> 466\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[0;32m    468\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    470\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\ssl.py:1311\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1308\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1309\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1310\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[0;32m   1312\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1313\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\ssl.py:1167\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1165\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1167\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[0;32m   1168\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1169\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "a9290d23bf9d7a73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
